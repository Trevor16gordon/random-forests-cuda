{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "4Hjhy7KBLqle",
    "outputId": "e57e8b87-aacc-4c5f-fe03-59a083bf76cf"
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import sys\n",
    "# # sys.path.append(\"\")\n",
    "# if \"/home/ecbm4040/project/random-forests-cuda/\" not in sys.path:\n",
    "#     sys.path.insert(0, \"/home/ecbm4040/project/random-forests-cuda/\")\n",
    "# from src.python.cuda_utils import CudaUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CUDA devices available:  1\n",
      "Device Name: Tesla T4\n",
      "Compute Capability: 7.5\n",
      "Total Device Memory: 15109 megabytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pycuda\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.gpuarray as gpuArray\n",
    "from pycuda.compiler import SourceModule\n",
    "from numpy import unravel_index\n",
    "import pdb\n",
    "\n",
    "cuda.init()\n",
    "print(\"Number of CUDA devices available: \", cuda.Device.count())\n",
    "my_device = cuda.Device(0)\n",
    "# cc: compute capability\n",
    "cc = float('%d.%d' % my_device.compute_capability())\n",
    "print('Device Name: {}'.format(my_device.name()))\n",
    "print('Compute Capability: {}'.format(cc))\n",
    "print('Total Device Memory: {} megabytes'.format(my_device.total_memory()//1024**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_random_data(num_dimensions=3, num_samples=100, num_classes=3, random_state=None):\n",
    "    # Random weighted amounts of each class\n",
    "    random_states = list(range(random_state, random_state+3+num_classes*num_dimensions))\n",
    "    np.random.seed(random_states.pop(0))\n",
    "    cls_probs = np.array([0] + sorted(np.random.uniform(size=(num_classes - 1))) + [1])\n",
    "    cls_probs = cls_probs[1:] - cls_probs[:-1]\n",
    "    cls_num_samples = [int(num_samples*p) for p in cls_probs]\n",
    "    cls_num_samples[0] += num_samples - sum(cls_num_samples)\n",
    "    np.random.seed(random_states.pop(0))\n",
    "    means = np.random.normal(1, 10, size=(num_classes,num_dimensions))\n",
    "    np.random.seed(random_states.pop(0))\n",
    "    std = np.random.uniform(1, 10, size=(num_classes,num_dimensions))\\\n",
    "    \n",
    "    X = np.zeros((num_samples, num_dimensions))\n",
    "    y = np.zeros((num_samples, 1))\n",
    "    offset = 0\n",
    "    for class_i in range(num_classes):\n",
    "        y[offset:offset+cls_num_samples[class_i]] = class_i\n",
    "        for dim in range(num_dimensions):\n",
    "            np.random.seed(random_states.pop(0))\n",
    "            X[offset:offset+cls_num_samples[class_i], dim] = np.random.normal(means[class_i,dim],\n",
    "                                                                          std[class_i,dim],\n",
    "                                                                          size=cls_num_samples[class_i])\n",
    "        offset += cls_num_samples[class_i]\n",
    "        \n",
    "    X, y = shuffle(X, y)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTreeCudaUtils():\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Attributes for instance of EncoderDecoder module\n",
    "        \"\"\"\n",
    "        return\n",
    "    \n",
    "    def get_source_module(self):\n",
    "        # kernel code wrapper\n",
    "        kernelwrapper = \"\"\"\n",
    "        // Helps in the calculation of the gina scores\n",
    "        __global__ void calculate_gina_scores(float* impurity_scores,float* X_train,int* y_train,const int unique_classes,const int l,const int w){\n",
    "            int Dim = threadIdx.y+blockIdx.y*blockDim.y;\n",
    "            int Row = threadIdx.x+blockIdx.x*blockDim.x;\n",
    "\n",
    "            if(Dim < w && Row < l){\n",
    "                float split_value =X_train[Row * w+ Dim];\n",
    "\n",
    "                float group1_counts[20] = {0};//Max of 20 dimensions which can be increased\n",
    "                float group2_counts[20] = {0};\n",
    "                float length1=0;\n",
    "                float length2=0;\n",
    "                float sum1=0;\n",
    "                float sum2=0;\n",
    "\n",
    "                for(int i=0;i<l;i++){\n",
    "                    if(X_train[i* w+ Dim]>=split_value){\n",
    "                        //Belongs to group 1\n",
    "                        group1_counts[y_train[i]]++;\n",
    "                        length1++;\n",
    "                    }\n",
    "                    else{\n",
    "                        //Belongs to group 2\n",
    "                        group2_counts[y_train[i]]++;\n",
    "                        length2++;\n",
    "                    }\n",
    "                }\n",
    "                float p1 = length1/(length1+length2);\n",
    "                float p2 = length2/(length1+length2);\n",
    "\n",
    "                if(length1 > 0){\n",
    "                    for(int i=0;i<unique_classes;i++){\n",
    "                        sum1+=(group1_counts[i]*group1_counts[i])/(length1*length1);\n",
    "                    }\n",
    "                }\n",
    "                if(length2 > 0){\n",
    "                    for(int i=0;i<unique_classes;i++){\n",
    "                        sum2+=(group2_counts[i]*group2_counts[i])/(length2*length2);\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                float impurity = p1*sum1+p2*sum2;\n",
    "                // Write our new pixel value out\n",
    "                impurity_scores[Row * w + Dim] =impurity;\n",
    "\n",
    "            }\n",
    "        }\n",
    "\n",
    "        //////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "        //Finds the max value of all the gina impurity scores that we have calculated\n",
    "        #define BLOCKSIZE 1024\n",
    "        __global__ void find_best_gina_score(int* index, float* all_gina_scores, const int len){\n",
    "            //loading segment of data in local memory\n",
    "            __shared__ float scan_array[2*BLOCKSIZE];\n",
    "            __shared__ float ii_array[2*BLOCKSIZE];\n",
    "            unsigned int t =threadIdx.x;\n",
    "            unsigned int start=2*blockIdx.x*blockDim.x;\n",
    "\n",
    "            if(start+t <len){\n",
    "                scan_array[t]=all_gina_scores[start+t];\n",
    "                ii_array[t]=index[start+t];\n",
    "            }\n",
    "            if(start+blockDim.x+t <len){\n",
    "                scan_array[blockDim.x+t]=all_gina_scores[start+blockDim.x+t];\n",
    "                ii_array[blockDim.x+t]=index[start+blockDim.x+t];\n",
    "            }\n",
    "\n",
    "            for (unsigned int stride = blockDim.x;stride > 0; stride /= 2){\n",
    "                __syncthreads();\n",
    "                if (t < stride){\n",
    "                  \n",
    "                  if(scan_array[t] < scan_array[t+stride]){\n",
    "                      scan_array[t]=scan_array[t+stride];\n",
    "                      ii_array[t]= ii_array[t+stride];\n",
    "                  }\n",
    "                }            \n",
    "            }\n",
    "            __syncthreads();\n",
    "            if(threadIdx.x==0){\n",
    "                index[blockIdx.x] = ii_array[threadIdx.x];\n",
    "                all_gina_scores[blockIdx.x] =scan_array[threadIdx.x];\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        //////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "        //takes the input matrix X and returns the labels for l or r\n",
    "        __global__ void split_data(float* label,float* X, const int bound,const int dim, const int l,const int w){\n",
    "            int Row = threadIdx.x+blockIdx.x*blockDim.x;\n",
    "            if(Row < l){\n",
    "                if(X[Row*w+dim] <= bound){\n",
    "                    label[Row]=1;\n",
    "                }\n",
    "                else{\n",
    "                    label[Row]=0;\n",
    "                }\n",
    "            }           \n",
    "        }\n",
    "        \"\"\"\n",
    "        return SourceModule(kernelwrapper)\n",
    "         \n",
    "    def calculate_score(self, X_train_b, y_train_b):\n",
    "        \n",
    "        \n",
    "        if not isinstance(X_train_b, np.ndarray):\n",
    "            raise Exception(\"X_train_b needs to be np.array\")\n",
    "        if not isinstance(y_train_b, np.ndarray):\n",
    "            raise Exception(\"y_train_b needs to be np.array\")\n",
    "            \n",
    "        y_train_b = y_train_b.astype(np.float32)\n",
    "        X_train_b = X_train_b.astype(np.float32)\n",
    "            \n",
    "        # Implement CUDA function\n",
    "        \n",
    "        self.mod = self.get_source_module()\n",
    "\n",
    "        unique_classes = np.unique(y_train_b)\n",
    "        #Making categorical data into integers\n",
    "        for j,label in enumerate(unique_classes):\n",
    "            y_train_b[y_train_b == label]=j\n",
    "        \n",
    "        #Fetch the kernel\n",
    "        start =cuda.Event()\n",
    "        end = cuda.Event()\n",
    "\n",
    "        calculate_scores=self.mod.get_function(\"calculate_gina_scores\")\n",
    "\n",
    "        #Converting to 32 bit\n",
    "        X_train_b = X_train_b.astype(np.float32)\n",
    "        y_train_b =y_train_b.astype(np.int32)\n",
    "\n",
    "        unique_classes=np.array(len(unique_classes)).astype(np.int32)\n",
    "        row = np.array(X_train_b.shape[0]).astype(np.int32)\n",
    "        dim = np.array(X_train_b.shape[1]).astype(np.int32)\n",
    "\n",
    "        #Grid and block dimensions\n",
    "        blocksize=32\n",
    "#         blockDim=(blocksize,X_train_b.shape[1],1)\n",
    "        blockDim=(blocksize, blocksize, 1)\n",
    "        gridDim =(X_train_b.shape[0]//blocksize+1, X_train_b.shape[1]//blocksize+1, 1)\n",
    "\n",
    "        #Memory allocation\n",
    "        X_train_b_gpu = gpuArray.to_gpu(X_train_b)\n",
    "        y_train_b_gpu = gpuArray.to_gpu(y_train_b)  \n",
    "        impurity_scores_gpu = gpuArray.zeros_like(X_train_b_gpu)\n",
    "        \n",
    "        #run and time the kernel\n",
    "        start.record()\n",
    "        print(blockDim)\n",
    "        print(gridDim)\n",
    "        calculate_scores(impurity_scores_gpu,\n",
    "                         X_train_b_gpu,\n",
    "                         y_train_b_gpu,\n",
    "                         unique_classes,\n",
    "                         row,\n",
    "                         dim,\n",
    "                         block=blockDim,\n",
    "                         grid=gridDim)\n",
    "\n",
    "        # Wait for the event to complete\n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "        time = start.time_till(end)\n",
    "\n",
    "        #Fetch the impurity scores\n",
    "        impurity_scores = impurity_scores_gpu.get()\n",
    "        return impurity_scores\n",
    "    \n",
    "    def choose_best_score(self, all_gina_scores: np.array):\n",
    "        \n",
    "        if not isinstance(all_gina_scores, np.ndarray):\n",
    "            raise Exception(\"all_gina_scores needs to be np.array\")\n",
    "        all_gina_scores = all_gina_scores.astype(np.float32)\n",
    "        \n",
    "        all_gina_scores_flatten = all_gina_scores.flatten()\n",
    "        \n",
    "        current_scores = all_gina_scores_flatten\n",
    "        current_indexes = np.array([i for i in range(all_gina_scores_flatten.shape[0])])\n",
    "        current_indexes = current_indexes.astype(np.int32)\n",
    "        \n",
    "        t_total = 0\n",
    "        count = 0\n",
    "        block_size = 8\n",
    "        while True:\n",
    "            \n",
    "            new_current_indexes, new_current_scores, t = self.choose_best_score_recurs(current_scores, current_indexes)\n",
    "            t_total += t\n",
    "            count += 1\n",
    "            \n",
    "            \n",
    "            if len(current_indexes) <= block_size:\n",
    "                #print(f\"breaking becuase len(current_indexes) is {len(current_indexes)}\")\n",
    "                break\n",
    "                \n",
    "            current_scores, current_indexes = new_current_scores, new_current_indexes\n",
    "            \n",
    "            \n",
    "        max_index=unravel_index(int(current_indexes[0]), all_gina_scores.shape)\n",
    "        return max_index\n",
    "    \n",
    "    \n",
    "\n",
    "    def choose_best_score_recurs(self, all_gina_scores_flatten, current_indexes):\n",
    "        #Unravel the matrix\n",
    "        \n",
    "        self.mod = self.get_source_module()\n",
    "        \n",
    "\n",
    "        #Fetch the kernel \n",
    "        # start =cuda.Event()\n",
    "        # end = cuda.Event()\n",
    "\n",
    "        find_best_gina_score=self.mod.get_function(\"find_best_gina_score\")\n",
    "        #setting up the eindex matrix\n",
    "        index = current_indexes\n",
    "\n",
    "\n",
    "        #Grid and block dimensions\n",
    "        block_size = 1024\n",
    "        blockDim=(block_size,1,1)\n",
    "        num_blocks = all_gina_scores_flatten.shape[0]//block_size+1\n",
    "        gridDim =(num_blocks,1,1)\n",
    "        print(f\"num_blocks {num_blocks}\")\n",
    "\n",
    "        #Converting to 32 bit\n",
    "        row =np.float32(all_gina_scores_flatten.shape[0])\n",
    "        all_gina_scores_flatten=all_gina_scores_flatten.astype(np.float32)\n",
    "\n",
    "        #memory allocation\n",
    "        all_gina_scores_gpu=gpuArray.to_gpu(all_gina_scores_flatten)\n",
    "        index=index.astype(np.int32)\n",
    "        index_gpu=gpuArray.to_gpu(index)\n",
    "\n",
    "        #run and time the kernel\n",
    "        # start.record()\n",
    "        find_best_gina_score(index_gpu,all_gina_scores_gpu,row,block=blockDim,grid=gridDim)\n",
    "\n",
    "        # Wait for the event to complete\n",
    "        # end.record()\n",
    "        # end.synchronize()\n",
    "        # time = start.time_till(end)\n",
    "\n",
    "        #Fetch the impurity scores\n",
    "        index=index_gpu.get()\n",
    "        gina_scores=all_gina_scores_gpu.get()\n",
    "        \n",
    "        \n",
    "        \n",
    "        pdb.set_trace()\n",
    "        #max_index=unravel_index()\n",
    "\n",
    "        return index[:num_blocks], gina_scores[:num_blocks], 0\n",
    "\n",
    "    def split_data(self, X: np.array, y: np.array, bound: float, dim: float):\n",
    "        \n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise Exception(\"X needs to be np.array\")\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise Exception(\"y needs to be np.array\")\n",
    "\n",
    "        self.mod = self.get_source_module()\n",
    "        # Implement CUDA function\n",
    "        #Fetch the kernel\n",
    "        start =cuda.Event()\n",
    "        end = cuda.Event()\n",
    "\n",
    "        split_data=self.mod.get_function(\"split_data\")\n",
    "        #Grid and block dimensions\n",
    "        blockDim=(1024,1,1)\n",
    "        gridDim =(X.shape[0]//1024+1,1,1)\n",
    "        #Converting to 32 bit\n",
    "        labels = np.zeros(y.shape).astype(np.float32)\n",
    "        X_32 = X.astype(np.float32)\n",
    "        row = np.array([X.shape[0]], dtype=np.int32)\n",
    "        col = np.array([X.shape[1]], dtype=np.int32)\n",
    "        bound = np.array([bound], dtype=np.int32)\n",
    "        dim =np.array([dim], dtype=np.int32)\n",
    "        #Memory allocation\n",
    "        X_gpu = gpuArray.to_gpu(X_32) \n",
    "        labels_gpu = gpuArray.to_gpu(labels)\n",
    "\n",
    "        #run and time the kernel\n",
    "        start.record()\n",
    "        split_data(labels_gpu,X_gpu,bound,dim,row,col,block=blockDim,grid=gridDim)\n",
    "\n",
    "        # Wait for the event to complete\n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "        time = start.time_till(end)\n",
    "\n",
    "        #Fetch the impurity scores\n",
    "        labels = labels_gpu.get().reshape(-1,)\n",
    "\n",
    "        #code for splitting the child\n",
    "#         print(labels==0)\n",
    "        y_l = y[labels==1]\n",
    "        y_r = y[labels==0]\n",
    "#         print(y_l,y_r)\n",
    "#         print(X[0][:])\n",
    "#         print(f\"X.shape is {X.shape}\")\n",
    "#         print(f\"labels.shape is {labels.shape}\")\n",
    "        X_l = X[labels==1,:]\n",
    "        X_r = X[labels==0,:]\n",
    "        return (X_l, y_l, X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import src.python.random_forest\n",
    "imp.reload(src.python.random_forest)\n",
    "from src.python.random_forest import RandomForestFromScratch, DecisionTreeNativePython, DecisionTreeCudaBaise\n",
    "# rf = RandomForestFromScratch(max_depth=3, n_estimators=1)\n",
    "# rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = generate_random_data(num_dimensions=3, num_samples=100, num_classes=3, random_state=153)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3)\n",
    "X_train, y_train = X_all, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_gina_scores = DecisionTreeNativePython(max_depth=3).calculate_split_scores(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtu = DecisionTreeCudaUtils()\n",
    "(ref_X_l, ref_y_l, ref_X_r, ref_y_r) = DecisionTreeNativePython(max_depth=3).split_data(X_train, y_train, 4, 0)\n",
    "(X_l, y_l, X_r, y_r) = dtu.split_data(X_train, y_train, 4, 0)\n",
    "\n",
    "print(np.allclose(ref_X_l, X_l))\n",
    "print(np.allclose(ref_y_l, y_l))\n",
    "print(np.allclose(ref_X_r, X_r))\n",
    "print(np.allclose(ref_y_r, y_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impurity_scores =  dtu.calculate_score.calculate_split_scores(X_train, y_train)\n",
    "np.allclose(impurity_scores, ref_gina_scores, atol=0.01)\n",
    "# np.count_nonzero(np.abs(impurity_scores - ref_gina_scores) > 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference max index is: (1585, 4)\n",
      "num_blocks 74\n",
      "num_blocks 1\n",
      "num_blocks 1\n",
      "1585 4\n"
     ]
    }
   ],
   "source": [
    "dtu = DecisionTreeCudaUtils()\n",
    "print(\"Reference max index is:\" , np.unravel_index(np.argmax(ref_gina_scores), ref_gina_scores.shape))\n",
    "max_index, max_score = dtu.choose_best_score(ref_gina_scores)\n",
    "print(max_index, max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_scores = data.flatten()\n",
    "# current_indexes = [i for i in range(len(data.flatten()))]\n",
    "# block_indexes, current_scores, t = dtu.choose_best_score_recurs(current_scores, current_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Cuda RF\n",
    "\n",
    "dtu = DecisionTreeCudaUtils()\n",
    "dt_cuda = DecisionTreeCudaBaise(max_depth=4)\n",
    "dt_cuda.calculate_split_scores = dtu.calculate_score\n",
    "dt_cuda.choose_best_score = dtu.choose_best_score\n",
    "dt_cuda.split_data = dtu.split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "(4, 1, 1)\n",
      "num_blocks 1\n",
      "> \u001b[0;32m<ipython-input-71-889a17bcbe65>\u001b[0m(262)\u001b[0;36mchoose_best_score_recurs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    260 \u001b[0;31m        \u001b[0;31m#max_index=unravel_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 262 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgina_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    264 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "num_blocks 1\n",
      "> \u001b[0;32m<ipython-input-71-889a17bcbe65>\u001b[0m(262)\u001b[0;36mchoose_best_score_recurs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    260 \u001b[0;31m        \u001b[0;31m#max_index=unravel_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 262 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgina_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    264 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(index)         print(gina_scores)\n",
      "*** SyntaxError: invalid syntax\n",
      "ipdb> print(index);print(gina_scores)\n",
      "[182]\n",
      "[0.7725806]\n",
      "ipdb> c\n",
      "(32, 32, 1)\n",
      "(2, 1, 1)\n",
      "num_blocks 1\n",
      "> \u001b[0;32m<ipython-input-71-889a17bcbe65>\u001b[0m(262)\u001b[0;36mchoose_best_score_recurs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    260 \u001b[0;31m        \u001b[0;31m#max_index=unravel_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    261 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 262 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgina_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_blocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    264 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(index);print(gina_scores)\n",
      "[1061279680          1          2          3          4          5\n",
      "          6          7          8          9         10         11\n",
      "         12         13         14         15         16         17\n",
      "         18         19         20         21         22         23\n",
      "         24         25         26         27         28         29\n",
      "         30         31         32         33         34         35\n",
      "         36         37         38         39         40         41\n",
      "         42         43         44         45         46         47\n",
      "         48         49         50         51         52         53\n",
      "         54         55         56         57         58         59\n",
      "         60         61         62         63         64         65\n",
      "         66         67         68         69         70         71\n",
      "         72         73         74         75         76         77\n",
      "         78         79         80         81         82         83\n",
      "         84         85         86         87         88         89\n",
      "         90         91         92         93         94         95\n",
      "         96         97         98         99        100        101\n",
      "        102        103        104        105        106        107\n",
      "        108        109        110        111        112        113\n",
      "        114        115        116        117        118        119\n",
      "        120        121        122        123        124        125\n",
      "        126        127        128        129        130        131\n",
      "        132        133        134        135        136        137\n",
      "        138        139        140        141        142        143\n",
      "        144        145        146        147        148        149\n",
      "        150        151        152        153        154        155\n",
      "        156        157        158        159        160        161\n",
      "        162        163        164        165        166        167\n",
      "        168        169        170        171        172        173\n",
      "        174        175        176        177        178        179\n",
      "        180        181        182        183        184        185]\n",
      "[33.336643    0.64124423  0.63709676  0.68108505  0.7145855   0.6342375\n",
      "  0.76640713  0.733565    0.637312    0.7340124   0.7563364   0.6436026\n",
      "  0.7360704   0.7997518   0.6332608   0.6642528   0.6434635   0.6378772\n",
      "  0.79528534  0.63319457  0.63892084  0.8496466   0.6631201   0.6349846\n",
      "  0.6457373   0.65307367  0.63486946  0.7580645   0.74470514  0.6340664\n",
      "  0.9090323   0.63591397  0.6557072   0.71229297  0.6412681   0.6403509\n",
      "  0.67150533  0.73527354  0.6375779   0.8043255   0.7807262   0.6364919\n",
      "  0.67391306  0.635256    0.6381635   0.85421836  0.6916348   0.63515794\n",
      "  0.7502601   0.63914704  0.63320357  0.70713073  0.7483413   0.63319457\n",
      "  0.658444    0.6753382   0.6457373   0.63914704  0.7064516   0.6363186\n",
      "  0.6412681   0.6709677   0.63844085  0.7296015   0.6480938   0.6343171\n",
      "  0.78494626  0.8034648   0.6335125   0.63511366  0.6596006   0.6344913\n",
      "  0.76990414  0.6432505   0.6342707   0.86811656  0.63709676  0.6412681\n",
      "  0.7804188   0.7633448   0.63511366  0.93811715  0.77534324  0.63643265\n",
      "  0.6849212   0.6504669   0.63865215  0.63709676  0.65632755  0.6335926\n",
      "  0.8179911   0.6663633   0.63914704  0.93832076  0.7572001   0.6366585\n",
      "  0.9119916   0.6532869   0.6480938   0.6557072   0.6754395   0.63511366\n",
      "  0.7918509   0.6707102   0.63322586  0.6705559   0.64785844  0.63525194\n",
      "  0.7429435   0.7235791   0.6359073   0.88108796  0.67150533  0.6398076\n",
      "  0.82836276  0.7124583   0.6377539   0.693155    0.6457373   0.6360317\n",
      "  0.6480938   0.6505376   0.6434635   0.6505376   0.6336405   0.63424563\n",
      "  0.96841395  0.6332608   0.6376344   0.66733867  0.63511366  0.6505376\n",
      "  0.70223325  0.6343171   0.6395161   0.8887624   0.6923458   0.6371701\n",
      "  0.67741936  0.64303374  0.63325655  0.65203595  0.6623656   0.6420611\n",
      "  0.6434635   0.68059003  0.63515264  0.7124583   0.7794721   0.64526886\n",
      "  0.75633645  0.6409429   0.63431257  0.7794721   0.7764361   0.64440304\n",
      "  0.65307367  0.6990686   0.6336036   0.69758064  0.8010753   0.63535243\n",
      "  0.63319457  0.6454546   0.64141977  0.8330261   0.6378299   0.6422668\n",
      "  0.7753456   0.6862075   0.635256    0.66129035  0.66690266  0.64303374\n",
      "  0.6916348   0.65203595  0.6377891   0.7177419   0.63643265  0.65307367\n",
      "  0.8034648   0.7340124   0.6385267   0.7235023   0.6394362   0.6340441 ]\n",
      "ipdb> current_indexes\n",
      "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dt_cuda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPEseq+Gs+dPY7HtmnpNTTL",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "PyCUDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
